{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T14:59:29.576245Z",
     "start_time": "2025-03-01T14:59:19.695378Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import optuna\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63614f970c805f8",
   "metadata": {},
   "source": [
    "## Demo 1\n",
    "Find the value of x that minimizes the function: f(x) = (x - 2)^2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504af71da0eb537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the value of x that minimizes the function: f(x) = (x - 2)^2 + 1\n",
    "\n",
    "def objective(trial):\n",
    "    pass\n",
    "\n",
    "# Create and run study\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac851427f9ba63e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{study.best_params = }\")\n",
    "print(f\"{study.best_value = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451f0d4a91424b9e",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Find the values of x and y that mininize the function: f(x,y) = (x - 2)^2 + (y + 3)^2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db959359de5a418e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T14:52:23.534636Z",
     "start_time": "2025-02-22T14:52:23.534636Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    pass\n",
    "\n",
    "# Create and run study\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc01d35df4708955",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87479a0e2916e76d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T14:52:23.535637Z",
     "start_time": "2025-02-22T14:52:23.534636Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the optimization process\n",
    "\n",
    "# Get optimization history\n",
    "optuna.visualization.plot_optimization_history(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c43464e166ebf19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T14:52:23.536304Z",
     "start_time": "2025-02-22T14:52:23.536304Z"
    }
   },
   "outputs": [],
   "source": [
    "# You can also visualize parameter importance\n",
    "optuna.visualization.plot_param_importances(study)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8da7b1cac4f1dba",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a37b26a483f1d5c2",
   "metadata": {},
   "source": [
    "## Optimize LightGBM estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f496e6866d73d403",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a48afba5ff0a36a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T15:00:13.363391Z",
     "start_time": "2025-02-22T15:00:13.352938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (569, 30)\n",
      "\n",
      "Target distribution:\n",
      "Malignant (0): 212\n",
      "Benign (1): 357\n",
      "\n",
      "Features: ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare data\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = load_breast_cancer()\n",
    "print(f\"Dataset shape: {data.data.shape}\")  # 569 samples, 30 features\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(f\"Malignant (0): {(data.target == 0).sum()}\")\n",
    "print(f\"Benign (1): {(data.target == 1).sum()}\")\n",
    "print(\"\\nFeatures:\", data.feature_names.tolist())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data, data.target, test_size=0.2, random_state=42\n",
    ")\n",
    "feature_names = data.feature_names.tolist()\n",
    "X_train = pd.DataFrame(X_train, columns=feature_names)\n",
    "X_test = pd.DataFrame(X_test, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4326907b1349d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 50),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'verbose': -1  # Add this to suppress LightGBM logger\n",
    "\n",
    "    }\n",
    "    \n",
    "    # Create model with suggested hyperparameters\n",
    "    model = LGBMClassifier(**params, random_state=42)\n",
    "    \n",
    "    # Use cross-validation to evaluate the model\n",
    "    cv_scores = cross_val_score(\n",
    "        model, \n",
    "        X_train, \n",
    "        y_train, \n",
    "        cv=5,\n",
    "        scoring='accuracy'\n",
    "    )\n",
    "    \n",
    "    # Return mean CV score\n",
    "    return cv_scores.mean()  \n",
    "\n",
    "# Create and run study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf671c47ae1a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{study.best_params}\")\n",
    "print(f\"{study.best_value * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44fe6382f166fb8",
   "metadata": {},
   "source": [
    "## Exercise 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e57b11f05ad807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# Using the same breast cancer dataset defined above\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_rate=0.1):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.layer = nn.Linear(input_size, hidden_size)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.output = nn.Linear(hidden_size, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, device='cpu'):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cpu'):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "def objective(trial):\n",
    "    # Student Task 1: Define hyperparameters to optimize\n",
    "    # Use trial.suggest_float, trial.suggest_int, etc.\n",
    "    # Example format:\n",
    "    # hidden_size = trial.suggest_int('hidden_size', min_value, max_value)\n",
    "    # learning_rate = \n",
    "    # dropout_rate = \n",
    "    # batch_size = \n",
    "    # n_epochs = \n",
    "    \n",
    "    # Create model and move to device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = SimpleNet(input_size=20, \n",
    "                     hidden_size=hidden_size, \n",
    "                     dropout_rate=dropout_rate).to(device)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = train_model(model, train_loader, criterion, optimizer, device)\n",
    "        accuracy = evaluate_model(model, test_loader, device)\n",
    "        \n",
    "        # Enable pruning (early stopping) based on accuracy\n",
    "        trial.report(accuracy, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    \n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cde1d0a1caff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, timeout=60)\n",
    "\n",
    "# TODO:\n",
    "# Print best trial information\n",
    "# Create visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ff9d64",
   "metadata": {},
   "source": [
    "## FLAML Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af780c89",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AutoML' from 'flaml' (/Users/somto/Documents/projects/tutorial-seven/.venv/lib/python3.12/site-packages/flaml/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, roc_auc_score\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mflaml\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoML\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize the AutoML object\u001b[39;00m\n\u001b[1;32m      6\u001b[0m automl \u001b[38;5;241m=\u001b[39m AutoML()\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'AutoML' from 'flaml' (/Users/somto/Documents/projects/tutorial-seven/.venv/lib/python3.12/site-packages/flaml/__init__.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from flaml import AutoML\n",
    "\n",
    "\n",
    "# Initialize the AutoML object\n",
    "automl = AutoML()\n",
    "\n",
    "# Configure and train the model\n",
    "# We'll specify multiple estimators for FLAML to try\n",
    "automl.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    task=\"classification\",  # Specify the task (classification in this case)\n",
    "    time_budget=60,  # Time budget in seconds\n",
    "    metric=\"accuracy\",  # Optimization metric\n",
    "    # List of estimators to try\n",
    "    estimator_list=[\"lgbm\", \"rf\", \"xgboost\", \"extra_tree\", \"catboost\"],  \n",
    "    verbose=2  # Verbosity level\n",
    ")\n",
    "\n",
    "# Get the best model\n",
    "best_model = automl.model\n",
    "\n",
    "# Print information about the best model found\n",
    "print(\"\\n----- Best Model Information -----\")\n",
    "print(f\"Best model: {automl.best_estimator}\")\n",
    "print(f\"Best configuration: {automl.best_config}\")\n",
    "print(f\"Training accuracy: {automl.best_loss * -1 if automl.best_loss < 0 else automl.best_loss}\")\n",
    "print(f\"Time taken: {automl.best_config_train_time:.2f} seconds\")\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate on test data\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"\\n----- Test Performance -----\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test AUC: {test_auc:.4f}\")\n",
    "\n",
    "# Summarize all models FLAML tried, ordered from best to worst\n",
    "print(\"\\n----- All Models Evaluated -----\")\n",
    "for i, (estimator, config, loss, train_time) in enumerate(\n",
    "    zip(\n",
    "        automl.estimator_list, \n",
    "        automl.config_list, \n",
    "        automl.loss_list, \n",
    "        automl.time_list\n",
    "    )\n",
    "):\n",
    "    print(f\"{i+1}. {estimator} - Accuracy: {-loss if loss < 0 else loss:.4f}, Time: {train_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8acc3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
